{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Пожалуйста, делайте копию на свой Google Drive!"
      ],
      "metadata": {
        "id": "CUMOOnceRmqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сравнение методов сериализации"
      ],
      "metadata": {
        "id": "l1ZEIiVI2M9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime"
      ],
      "metadata": {
        "id": "D4J5VDIak_Mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b10741-3d01-4d3f-c5b8-8deca036c7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.20.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.25.5)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import onnx\n",
        "import onnxruntime\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Subset\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "PIDDM5RqmEt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9ITqGleomJUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка и подготовка данных (оставлено без изменений)\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        ")\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "num_samples = 1000\n",
        "indices = random.sample(range(len(train_set)), num_samples)\n",
        "limited_set = Subset(train_set, indices)\n",
        "train_loader = torch.utils.data.DataLoader(limited_set, batch_size=4, shuffle=True)"
      ],
      "metadata": {
        "id": "V23E484hmLfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ComplexCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "n_epoch = 2\n",
        "sep = \"-\" * 60\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "    print(sep)\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for data in tqdm(train_loader):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss)\n",
        "\n",
        "    epoch_loss = torch.mean(torch.tensor(losses))\n",
        "    print(f\"\\nLoss: {epoch_loss}\")\n",
        "else:\n",
        "    print(sep)\n",
        "    print(\"Обучение завершено\")"
      ],
      "metadata": {
        "id": "x1M0lRAYmVT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "806dc6c4-822d-43d6-e0a9-cef3b7e311a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "Epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:29<00:00,  8.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loss: 2.3070297241210938\n",
            "------------------------------------------------------------\n",
            "Epoch: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 250/250 [00:28<00:00,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loss: 2.3042705059051514\n",
            "------------------------------------------------------------\n",
            "Обучение завершено\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение модели различными способами\n",
        "\n",
        "# 1. PyTorch\n",
        "torch.save(model.state_dict(), \"cnn_pytorch.pth\")\n",
        "print(\"Модель сохранена в формате PyTorch\")\n",
        "\n",
        "# 2. Pickle\n",
        "with open(\"cnn_pickle.pkl\", \"wb\") as f:\n",
        "    pickle.dump(model, f)\n",
        "print(\"Модель сохранена в формате Pickle\")\n",
        "\n",
        "# 3. ONNX\n",
        "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
        "torch.onnx.export(model, dummy_input, \"cnn.onnx\", verbose=True)\n",
        "print(\"Модель сохранена в формате ONNX\")"
      ],
      "metadata": {
        "id": "CZA5u_U4mdHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2689b68b-af34-4cc6-e4d2-fe4e8f805ccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель сохранена в формате PyTorch\n",
            "Модель сохранена в формате Pickle\n",
            "Модель сохранена в формате ONNX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка моделей\n",
        "\n",
        "def print_load_time(start_time, model):\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    print(f\"Модель: {model}\")\n",
        "    print(f\"Время десереализации: {time.time() - start_time:.6f} секунд\")\n",
        "\n",
        "# 1. PyTorch\n",
        "start_time = time.time()\n",
        "pytorch_model = ComplexCNN().to(device)\n",
        "pytorch_model.load_state_dict(torch.load(\"cnn_pytorch.pth\"))\n",
        "pytorch_model.eval()\n",
        "print_load_time(start_time, \"PyTorch\")\n",
        "\n",
        "# 2. Pickle\n",
        "start_time = time.time()\n",
        "with open(\"cnn_pickle.pkl\", \"rb\") as f:\n",
        "    pickle_model = pickle.load(f)\n",
        "pickle_model.eval()\n",
        "print_load_time(start_time, \"Pickle\")\n",
        "\n",
        "# 3. ONNX\n",
        "start_time = time.time()\n",
        "onnx_model = onnx.load(\"cnn.onnx\")\n",
        "onnx.checker.check_model(onnx_model)\n",
        "ort_session = onnxruntime.InferenceSession(\"cnn.onnx\")\n",
        "print_load_time(start_time, \"ONNX\")\n",
        "\n",
        "print(\"\\nВсе модели загружены\")"
      ],
      "metadata": {
        "id": "oTPJnzfXo7Wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f395c49b-4064-4257-e09e-7424ae66f11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------\n",
            "Модель: PyTorch\n",
            "Время десереализации: 0.033295 секунд\n",
            "--------------------------------------------------------\n",
            "Модель: Pickle\n",
            "Время десереализации: 0.009754 секунд\n",
            "--------------------------------------------------------\n",
            "Модель: ONNX\n",
            "Время десереализации: 0.073164 секунд\n",
            "\n",
            "Все модели загружены\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_inference_time(model_func, input_tensor, num_iterations=1000):\n",
        "    times = []\n",
        "    for _ in range(num_iterations):\n",
        "        start_time = time.time()\n",
        "        _ = model_func(input_tensor)\n",
        "        end_time = time.time()\n",
        "        times.append(end_time - start_time)\n",
        "    return times\n",
        "\n",
        "def bootstrap_analysis(times, num_bootstrap=1000, confidence=0.95):\n",
        "    means = []\n",
        "    for _ in range(num_bootstrap):\n",
        "        sample = np.random.choice(times, size=len(times), replace=True)\n",
        "        means.append(np.mean(sample))\n",
        "\n",
        "    mean = np.mean(means)\n",
        "    ci_lower, ci_upper = np.percentile(means, [(1-confidence)/2 * 100, (1+confidence)/2 * 100])\n",
        "    return mean, ci_lower, ci_upper"
      ],
      "metadata": {
        "id": "rYzGWOSjxcw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подготовка входных данных\n",
        "input_tensor = torch.randn(1, 1, 28, 28).to(device)\n",
        "onnx_input = {ort_session.get_inputs()[0].name: input_tensor.cpu().numpy()}\n",
        "\n",
        "# Измерение времени инференса\n",
        "original_times = measure_inference_time(model, input_tensor)\n",
        "pytorch_times = measure_inference_time(pytorch_model, input_tensor)\n",
        "pickle_times = measure_inference_time(pickle_model, input_tensor)\n",
        "onnx_times = measure_inference_time(lambda x: ort_session.run(None, onnx_input), onnx_input)\n",
        "\n",
        "models = ['Original', 'PyTorch', 'Pickle', 'ONNX']\n",
        "times_list = [original_times, pytorch_times, pickle_times, onnx_times]"
      ],
      "metadata": {
        "id": "PE0FrcD_yF2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_name_length = max(len(name) for name in models)\n",
        "for model_name, times_ in zip(models, times_list):\n",
        "    print(f\"Среднее время инференса {model_name:<{max_name_length}}: {np.mean(times_):.6f} секунд\")"
      ],
      "metadata": {
        "id": "AW4p_ah1yI1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a658816-e6bf-462f-9aff-0967c3279f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднее время инференса Original: 0.010764 секунд\n",
            "Среднее время инференса PyTorch : 0.010528 секунд\n",
            "Среднее время инференса Pickle  : 0.010568 секунд\n",
            "Среднее время инференса ONNX    : 0.004927 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выполнение bootstrap-анализа\n",
        "sep_1 = \"=\" * 60\n",
        "sep_2 = \"-\" * 60\n",
        "\n",
        "print(sep_1)\n",
        "print(\"Результаты bootstrap-анализа (95% доверительный интервал):\")\n",
        "print(sep_2)\n",
        "for model_name, times_ in zip(models, times_list):\n",
        "    mean, ci_lower, ci_upper = bootstrap_analysis(times_)\n",
        "    print(f\"{model_name:<{max_name_length}}: {mean:.6f} секунд ({ci_lower:.6f} - {ci_upper:.6f})\")\n",
        "\n",
        "print()\n",
        "print(sep_1)\n",
        "print(\"Сравнение производительности:\")\n",
        "print(sep_2)\n",
        "for model_name, times_ in zip(models[1:], times_list[1:]):\n",
        "    speedup = np.mean(original_times) / np.mean(times_)\n",
        "    print(f\"Ускорение {model_name:<{max_name_length}}: {speedup:.2f}x\")\n",
        "\n",
        "# Статистический тест (t-test) для сравнения с оригинальной моделью\n",
        "print()\n",
        "print(sep_1)\n",
        "print(\"Статистическая значимость (p-value):\")\n",
        "print(sep_2)\n",
        "for model_name, times_ in zip(models[1:], times_list[1:]):\n",
        "    t_stat, p_value = stats.ttest_ind(original_times, times_)\n",
        "    print(f\"{model_name:<{max_name_length}} vs Original: p-value = {p_value}\")"
      ],
      "metadata": {
        "id": "XW__gCmptm8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e83304-7189-42e2-e6e9-6d35887e3379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Результаты bootstrap-анализа (95% доверительный интервал):\n",
            "------------------------------------------------------------\n",
            "Original: 0.010760 секунд (0.010585 - 0.010929)\n",
            "PyTorch : 0.010525 секунд (0.010349 - 0.010702)\n",
            "Pickle  : 0.010567 секунд (0.010392 - 0.010739)\n",
            "ONNX    : 0.004927 секунд (0.004899 - 0.004957)\n",
            "\n",
            "============================================================\n",
            "Сравнение производительности:\n",
            "------------------------------------------------------------\n",
            "Ускорение PyTorch : 1.02x\n",
            "Ускорение Pickle  : 1.02x\n",
            "Ускорение ONNX    : 2.18x\n",
            "\n",
            "============================================================\n",
            "Статистическая значимость (p-value):\n",
            "------------------------------------------------------------\n",
            "PyTorch  vs Original: p-value = 0.053917609493007425\n",
            "Pickle   vs Original: p-value = 0.103960973130923\n",
            "ONNX     vs Original: p-value = 0.0\n"
          ]
        }
      ]
    }
  ]
}